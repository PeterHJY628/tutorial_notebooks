{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/Depth_Anything_Reconstruction_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Depth Anything V1\n",
        "Paper: https://arxiv.org/pdf/2401.10891.pdf<br>\n",
        "Download a sample image"
      ],
      "metadata": {
        "id": "nY_I9UZs5Rph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1L3mKl7qlUGE47wZydUST2aTXlBKpN-oI"
      ],
      "metadata": {
        "id": "a4h5r201i-RR",
        "outputId": "fc4f4aa5-d2b7-4ffd-d03d-43d6db0c9b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1L3mKl7qlUGE47wZydUST2aTXlBKpN-oI\n",
            "To: /content/img.png\n",
            "\r  0% 0.00/1.55M [00:00<?, ?B/s]\r100% 1.55M/1.55M [00:00<00:00, 76.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mount the google drive"
      ],
      "metadata": {
        "id": "N-LdKgByPI7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZYcXqc6o-6a",
        "outputId": "2dc76ad2-2442-41b4-f226-ee00af98d2db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/endo_img/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUwsJka8PVaU",
        "outputId": "23636e94-8b2c-458a-ad74-266536693e8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install open3d"
      ],
      "metadata": {
        "id": "3Zy_6o4RSA29"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Depth and Reconstruction: All Together"
      ],
      "metadata": {
        "id": "eFt_8VXog9qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor, AutoModelForDepthEstimation, DepthAnythingForDepthEstimation\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import matplotlib\n",
        "import open3d as o3d\n",
        "import cv2\n",
        "import matplotlib as mpl\n",
        "import matplotlib.cm as cm\n",
        "import os\n",
        "\n",
        "def render_depth_v2(values, colormap_name=\"magma_r\") -> Image:\n",
        "    vmax = np.percentile(values, 95)\n",
        "    normalizer = mpl.colors.Normalize(vmin=values.min(), vmax=vmax)\n",
        "    mapper = cm.ScalarMappable(norm=normalizer, cmap='magma')\n",
        "    colormapped_im = (mapper.to_rgba(values)[:, :, :3] * 255).astype(np.uint8)\n",
        "    return Image.fromarray(colormapped_im)\n",
        "\n",
        "def reconstruct_pointcloud(rgb, depth, cam_K, vis_rgbd=False):\n",
        "\n",
        "    rgb = np.asarray(rgb, order=\"C\")\n",
        "    rgb_im = o3d.geometry.Image(rgb.astype(np.uint8))\n",
        "    depth_im = o3d.geometry.Image(depth)\n",
        "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(rgb_im, depth_im, convert_rgb_to_intensity=False)\n",
        "    if vis_rgbd:\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title('RGB image')\n",
        "        plt.imshow(rgbd_image.color)\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title('Depth image')\n",
        "        plt.imshow(rgbd_image.depth)\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "\n",
        "    cam = o3d.camera.PinholeCameraIntrinsic()\n",
        "    cam.intrinsic_matrix = cam_K\n",
        "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, cam)\n",
        "\n",
        "    return pcd\n",
        "\n",
        "def reconstruct_pointcloud_write(pred_depth, img_np, cam_K, ply_dir=None):\n",
        "\n",
        "    scale = 1 #200\n",
        "    MIN_DEPTH = 1e-3\n",
        "    MAX_DEPTH = 400\n",
        "    pred_depth *= scale\n",
        "    pred_depth[pred_depth < MIN_DEPTH] = MIN_DEPTH\n",
        "    pred_depth[pred_depth > MAX_DEPTH] = MAX_DEPTH\n",
        "    print('Final depth min:',pred_depth.min(), ', max:', pred_depth.max())\n",
        "    pcd = reconstruct_pointcloud(img_np, pred_depth, cam_K, vis_rgbd=False)\n",
        "    o3d.io.write_point_cloud(ply_dir, pcd)\n",
        "    print('3D Recon .ply saved in:', ply_dir)\n",
        "\n",
        "def img_to_mask(img, reduction=40):\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    #print(np.unique(img_gray))\n",
        "    mask = np.zeros(img_gray.shape)\n",
        "    mask_final = np.zeros(mask.shape)\n",
        "    mask[img_gray>0] = 255\n",
        "    #print(np.unique(mask), mask.shape)\n",
        "    mask = np.array(mask, np.uint8)\n",
        "    circles = cv2.HoughCircles(mask, cv2.HOUGH_GRADIENT, 3.5, 100)\n",
        "    if circles is not None:\n",
        "        #print('found')\n",
        "        circles = np.round(circles[0, :]).astype(\"int\")\n",
        "        (x, y, r) = circles[0:1][0]\n",
        "        cv2.circle(mask_final, (x, y), r-reduction, 1, -1)\n",
        "        img[mask_final==0] = 0\n",
        "    else: print('not found:')\n",
        "    return mask_final\n",
        "\n",
        "def depth_prediction(img, image_processor, model):\n",
        "    inputs = image_processor(images=img, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predicted_depth = outputs.predicted_depth\n",
        "\n",
        "\n",
        "    # print('raw input', img.size[::-1],'inputs',inputs['pixel_values'].shape, 'predicted_depth', predicted_depth.shape)\n",
        "    prediction = predicted_depth.clone()\n",
        "\n",
        "    #interpolate to original size\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        predicted_depth.unsqueeze(1),\n",
        "        size=img.size[::-1],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    )\n",
        "\n",
        "    output = prediction.squeeze().cpu().numpy()\n",
        "    return output\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "fx = 850.709\n",
        "# fx = 1050.709\n",
        "img_width =  1280\n",
        "img_height = 720\n",
        "intrinsics = np.array([[fx / img_width, 0, 0.5, 0],\n",
        "                [0, fx / img_height, 0.5, 0],\n",
        "                [0, 0, 1, 0],\n",
        "                [0, 0, 0, 1]])\n",
        "\n",
        "intrinsics[0,:] *= img_width\n",
        "intrinsics[1,:] *= img_height\n",
        "cam_K = intrinsics[:3,:3]\n",
        "\n",
        "# image_processor = AutoImageProcessor.from_pretrained(\"LiheYoung/depth-anything-small-hf\")\n",
        "# model = DepthAnythingForDepthEstimation.from_pretrained(\"LiheYoung/depth-anything-small-hf\").to(device)\n",
        "# model_weights = 'DA1_SMALL'\n",
        "\n",
        "# image_processor = AutoImageProcessor.from_pretrained(\"LiheYoung/depth-anything-large-hf\")\n",
        "# model = DepthAnythingForDepthEstimation.from_pretrained(\"LiheYoung/depth-anything-large-hf\").to(device)\n",
        "# model_weights = 'DA1_LARGE'\n",
        "\n",
        "# image_processor = AutoImageProcessor.from_pretrained(\"depth-anything/Depth-Anything-V2-Small-hf\")\n",
        "# model = DepthAnythingForDepthEstimation.from_pretrained(\"depth-anything/Depth-Anything-V2-Small-hf\").to(device)\n",
        "# model_weights = 'DA2_SMALL'\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(\"depth-anything/Depth-Anything-V2-Large-hf\")\n",
        "model = DepthAnythingForDepthEstimation.from_pretrained(\"depth-anything/Depth-Anything-V2-Large-hf\").to(device)\n",
        "model_weights = 'DA2_LARGE'\n",
        "\n",
        "recon_dir = \"/content/drive/MyDrive/endo_img/{}/PLY\".format(model_weights)\n",
        "depth_dir = \"/content/drive/MyDrive/endo_img/{}/Depth_Pred\".format(model_weights)\n",
        "imgs_dirs = glob(\"/content/drive/MyDrive/endo_img/imgs/*.png\")\n",
        "masked_imgs_dirs = \"/content/drive/MyDrive/endo_img/masked_imgs\"\n",
        "os.makedirs(recon_dir, mode = 0o777, exist_ok = True)\n",
        "os.makedirs(depth_dir, mode = 0o777, exist_ok = True)\n",
        "os.makedirs(masked_imgs_dirs, mode = 0o777, exist_ok = True)\n",
        "\n",
        "for img_dir in imgs_dirs:\n",
        "    img = Image.open(img_dir).convert(\"RGB\")\n",
        "    img_np = np.array(img)\n",
        "    mask = img_to_mask(img_np, reduction=35)\n",
        "    img_np[mask==0] = 0\n",
        "    img = Image.fromarray(img_np)\n",
        "    output = depth_prediction(img, image_processor, model)\n",
        "    mask = img_to_mask(img_np, reduction=40)\n",
        "    img_np[mask==0] = 0\n",
        "    output[mask==0] = 0\n",
        "    Image.fromarray(img_np).save(img_dir.replace('imgs', 'masked_imgs'))\n",
        "    vis_pred_depth = render_depth_v2(output/255)\n",
        "    file_name = os.path.basename(img_dir)\n",
        "    vis_pred_depth.save(os.path.join(depth_dir, file_name))\n",
        "    reconstruct_pointcloud_write(output, img_np, cam_K, ply_dir=os.path.join(recon_dir, file_name[:-3]+'ply'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91ncN-OG4kCw",
        "outputId": "0c831cfc-b4c0-4189-bd35-48bbb12d4018"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final depth min: 0.001 , max: 259.0529\n",
            "3D Recon .ply saved in: /content/drive/MyDrive/endo_img/DA2_LARGE/PLY/img.ply\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up scaling the pointcloud"
      ],
      "metadata": {
        "id": "_QxVM9Aa6F_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "\n",
        "# Load the depth image (16-bit PNG, assumed to be in millimeters or meters)\n",
        "depth_image = o3d.io.read_image(\"/content/drive/MyDrive/Datasets_Weights/Endonasal/recon2/DA2_LARGE/Depth_Pred/0004502.png\")\n",
        "print(np.array(depth_image).min(), np.array(depth_image).max())\n",
        "\n",
        "# Load the RGB image\n",
        "color_image = o3d.io.read_image(\"/content/drive/MyDrive/Datasets_Weights/Endonasal/recon2/masked_imgs/0004502.png\")\n",
        "\n",
        "# Ensure the depth image is in the correct format (convert if needed)\n",
        "depth_image_np = np.asarray(depth_image)\n",
        "if depth_image_np.dtype != np.float32:\n",
        "    depth_image_np = depth_image_np.astype(np.float32) / 100.0  # Convert from mm to meters if needed\n",
        "    depth_image = o3d.geometry.Image(depth_image_np)\n",
        "    print('if inside:', np.array(depth_image).min(), np.array(depth_image).max())\n",
        "\n",
        "# Create an RGBD image from the color and depth images\n",
        "rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
        "    color_image, depth_image, convert_rgb_to_intensity=False, depth_scale=1.0, depth_trunc=3.0\n",
        ")\n",
        "\n",
        "# Define the camera intrinsic parameters\n",
        "fx = 850.709  # focal length x\n",
        "fy = 850.709  # focal length y\n",
        "cx = 640  # principal point x\n",
        "cy = 360  # principal point y\n",
        "width = 1280\n",
        "height = 720\n",
        "\n",
        "# Create Open3D intrinsic object\n",
        "intrinsic = o3d.camera.PinholeCameraIntrinsic(width, height, fx, fy, cx, cy)\n",
        "\n",
        "# Create the point cloud from the RGBD image\n",
        "point_cloud = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
        "    rgbd_image, intrinsic\n",
        ")\n",
        "\n",
        "# Apply a scaling factor to the point cloud to make it bigger\n",
        "scaling_factor = 10.0  # Adjust this factor to scale the point cloud\n",
        "point_cloud.scale(scaling_factor, center=point_cloud.get_center())\n",
        "\n",
        "# Flip the point cloud (optional, for better visualization in Open3D's coordinate system)\n",
        "point_cloud.transform([[1, 0, 0, 0],\n",
        "                       [0, -1, 0, 0],\n",
        "                       [0, 0, -1, 0],\n",
        "                       [0, 0, 0, 1]])\n",
        "\n",
        "# Optionally, visualize the point cloud\n",
        "# o3d.visualization.draw_geometries([point_cloud])\n",
        "\n",
        "# Save the point cloud as a .ply file (with RGB colors)\n",
        "o3d.io.write_point_cloud(\"/content/drive/MyDrive/Datasets_Weights/Endonasal/recon2/0004502v2_4.ply\", point_cloud)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVe5fDDtIRuf",
        "outputId": "f844b001-6cb7-4188-8b75-58ac69582de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 254\n",
            "if inside: 0.0 2.54\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}