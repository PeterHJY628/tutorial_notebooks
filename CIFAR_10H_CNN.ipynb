{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-10H_CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterHJY628/tutorial_notebooks/blob/main/CIFAR_10H_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cloning repository of CIFAR-10H Annotation\n",
        "Paper: Human uncertainty makes classification more robust (https://arxiv.org/pdf/1908.07086.pdf)\n",
        "\n",
        "Label:  CIFAR10 [0: airplane, 1: automobile, 2: bird, 3: cat, 4: deer, 5: dog, 6: frog, 7: horse, 8: ship, 9: truck] <br>\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1010/1*r8S5tF_6naagKOnlIcGXoQ.png\" alt=\"alternatetext\">\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_vL2RMWddkaQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KrQIqW6_NYl",
        "outputId": "f39c390c-7441-4b56-c79d-3688c53b3d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cifar-10h'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 48 (from 1)\u001b[K\n",
            "Receiving objects: 100% (49/49), 10.85 MiB | 15.36 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "/content/cifar-10h\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jcpeterson/cifar-10h\n",
        "%cd cifar-10h"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main script"
      ],
      "metadata": {
        "id": "qNN4TybGd2Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn #provide layers AF LF\n",
        "import torch.optim as optim #optimizer\n",
        "import torch.nn.functional as F #provide function version of operation\n",
        "import torchvision #package for image data, db,process...\n",
        "from torchvision import models #pretrained and predefined model\n",
        "import torchvision.transforms as transforms #image preprocess and Data Augmentation\n",
        "import os #Interact with OS\n",
        "import argparse # help to parse command line argument and\n",
        "import copy #shallow copy: both change; deep copy: change one , original do not change\n",
        "import random\n",
        "import numpy as np\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "def seed_everything(seed=12):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)#分别为 PyTorch 的 CPU 和 GPU 操作设置随机种子。\n",
        "    np.random.seed(seed)#设置 NumPy 的随机数生成器的种子\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)#通过设置环境变量 PYTHONHASHSEED 来控制 Python 的哈希种子。这样可以确保在哈希操作中（如字典或集合的键）生成的结果是一致的，这在使用随机数据或模型时是很重要的。 确保 Python 的基于哈希的操作是确定性的\n",
        "    torch.backends.cudnn.deterministic = True #keep deterministic  保证 CUDA 操作的确定性。\n",
        "    torch.backends.cudnn.benchmark = False #no benchmark 禁用基准模式，使操作是确定性的，但可能会稍微降低运行速度。\n",
        "#help to adjust parameters like learning rate, batch size and so on\n",
        "parser = argparse.ArgumentParser(description='CIFAR-10H Training')\n",
        "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "parser.add_argument('--lr_schedule', default=0, type=int, help='lr scheduler')\n",
        "parser.add_argument('--batch_size', default=1024, type=int, help='batch size')\n",
        "parser.add_argument('--test_batch_size', default=2048, type=int, help='batch size')\n",
        "parser.add_argument('--num_epoch', default=100, type=int, help='epoch number')\n",
        "parser.add_argument('--num_classes', type=int, default=10, help='number classes')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "def train(model, trainloader, criterion, optimizer):\n",
        "    model.train()# change model to train mode\n",
        "    for batch_idx, (inputs, targets, ad) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)#forward\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()#update parameters of the model according to former calculated gradient\n",
        "\n",
        "def test(model, testloader):\n",
        "    model.eval()# change model to test mode\n",
        "    correct = 0#用于记录模型在测试集中预测正确的样本数。\n",
        "    total = 0#用于记录测试集中样本的总数。\n",
        "    with torch.no_grad():# no gradient calculation since no backward needed\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)#find the maximum value in the 1st dimension\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()#total += targets.size(0)：将当前批次的样本数累加到总样本数中。\n",
        "#predicted.eq(targets)：比较预测值与真实值，返回一个布尔张量，表示哪些样本的预测是正确的。\n",
        "#.sum().item()：将布尔张量中的 True 值（即正确预测的样本数）求和，并转换为 Python 的标量。\n",
        "#correct += ...：将本批次正确预测的数量累加到 correct 变量中。\n",
        "    return correct / total#return accuracy rate"
      ],
      "metadata": {
        "id": "NN371ewSCWX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR-10H dataloader"
      ],
      "metadata": {
        "id": "WHKUA3yBd87G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image# Python Imaging Library（PIL）中的 Image 模块的语句。PIL 是一个用于打开、操作和保存多种图像文件格式的库，而 Pillow 是其更现代的分支和替代品，目前广泛使用。使用这条导入语句时，我们实际上是在导入 Pillow 提供的 Image 模块。\n",
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "class CIFAR10H(torchvision.datasets.CIFAR10):#Inherit from torchvision.datasets.CIFAR10 class\n",
        "\n",
        "    def __init__(self, root,  rand_number=0, train=False, transform=None, target_transform=None,\n",
        "                 download=False):\n",
        "        super(CIFAR10H, self).__init__(root, train, transform, target_transform, download)\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.ad = np.load(os.path.join(root,'cifar10h-probs.npy'))#additional data\n",
        "    \"\"\"\n",
        "    self 允许引用当前实例\n",
        "    root：数据集的根目录。\n",
        "rand_number：一个随机数参数，这里没有使用。\n",
        "train：是否加载训练集。True 加载训练集，False 加载测试集。\n",
        "transform：应用于图像的转换（如数据增强、归一化等）。\n",
        "target_transform：应用于标签的转换。\n",
        "download：如果数据集不存在，是否自动下载。\n",
        "super(CIFAR10H, self).__init__(...) 调用父类的初始化方法，初始化标准 CIFAR-10 数据集。\n",
        "self.ad = np.load(os.path.join(root, 'cifar10h-probs.npy')) 加载一个名为 cifar10h-probs.npy 的文件，文件路径是 root 目录下。这通常是一个包含额外注释信息的 .npy 文件（NumPy 格式），例如 CIFAR-10H 数据集中的概率标签。\n",
        "    \"\"\"\n",
        "\n",
        "    def __getitem__(self, index: int):#用于获取数据集中的单个样本（图像、标签和附加数据\n",
        "        img, target = self.data[index], self.targets[index]#self.data 是包含所有图像的 NumPy 数组。self.targets 是包含所有图像标签的数组\n",
        "        img = Image.fromarray(img)#将 NumPy 数组格式的图像转换为 PIL 图像对象。这是因为许多图像处理操作在 PIL 图像对象上更方便。\n",
        "        ad = self.ad[index]#从 self.ad 中获取与当前索引对应的附加数据（如概率值或其他信息）。self.ad 是在类初始化时加载的 NumPy 数组，包含了与每个图像相关的附加信息。\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)#应用图像转换：如果指定了图像转换（self.transform），则对图像应用这些转换（如数据增强、归一化等）。这通常用于训练过程中，以提高模型的泛化能力。\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)#如果指定了标签转换（self.target_transform），则对目标标签应用这些转换。这可能用于将标签映射到其他形式，或者进行其他预处理操作。\n",
        "        return img, target, ad#方法返回一个包含图像、目标标签和附加数据的三元组。调用此方法时，可以获取到对应索引的完整样本信息。"
      ],
      "metadata": {
        "id": "z4uiWMiyCkjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run script"
      ],
      "metadata": {
        "id": "wRQEQIdaerKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "mean_cifar10, std_cifar10 = (0.5071, 0.4866, 0.4409), (0.2009, 0.1984, 0.2023)#均值与标准差：这些值是 CIFAR-10 数据集中每个通道（RGB）的均值和标准差，通常用于图像的标准化处理。mean_cifar10 是每个颜色通道的均值。std_cifar10 是每个颜色通道的标准差。\n",
        "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
        "            transforms.Normalize(mean_cifar10, std_cifar10), ])\n",
        "'''训练集的转换\n",
        "transforms.Compose([...])：将多个图像变换组合在一起。\n",
        "transforms.RandomCrop(32, padding=4)：随机裁剪图像为 32x32 像素，同时在边缘填充 4 个像素。这有助于增加图像的多样性。\n",
        "transforms.RandomHorizontalFlip()：以 50% 的概率随机水平翻转图像。这是另一种数据增强方式，用于提高模型的泛化能力。\n",
        "transforms.ToTensor()：将图像从 PIL 格式转换为 PyTorch 张量，并将像素值缩放到 [0, 1] 范围内。\n",
        "transforms.Normalize(mean_cifar10, std_cifar10)：使用之前定义的均值和标准差对图像进行标准化处理，使其均值为 0，标准差为 1，这样可以加速训练和提高模型的性能。'''\n",
        "\n",
        "transform_test = transforms.Compose([transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_cifar10, std_cifar10),])#测试集的转换\n",
        "\n",
        "train_dataset = CIFAR10H(root='./data', train=False, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_test)\n",
        "print('train samples:',len(train_dataset), 'test samples:',len(test_dataset))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
        "'''train_loader：使用 DataLoader 将训练数据集包装起来。设置 batch_size 为指定的批次大小，shuffle=True 表示在每个训练周期前随机打乱数据，以提高模型的泛化能力。num_workers=2 表示使用两个子进程来加载数据，加速数据读取。\n",
        "test_loader：类似于训练集的数据加载器，但 shuffle=False，因为在测试时不需要打乱数据。'''\n",
        "\n",
        "model = models.resnet34(pretrained=True).to(device)\n",
        "model.fc = nn.Linear(model.fc.in_features, args.num_classes)\n",
        "model = model.to(device)\n",
        "'''models.resnet34(pretrained=True)：加载预训练的 ResNet-34 模型。pretrained=True 表示使用在 ImageNet 数据集上训练的权重，这可以加速收敛并提高模型性能。\n",
        "model.fc = nn.Linear(model.fc.in_features, args.num_classes)：替换模型的最后一层（全连接层），使其输出的类别数量与 CIFAR-10 数据集的类别数量相匹配（即 args.num_classes）。\n",
        "model = model.to(device)：将模型移动到 GPU（如果可用）或 CPU。'''\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, nesterov=False, weight_decay=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "'''optim.SGD(...)：使用随机梯度下降（SGD）优化器。参数包括：\n",
        "model.parameters()：优化器将优化模型的参数。\n",
        "lr=args.lr：学习率。\n",
        "momentum=0.9：动量项，帮助加速SGD在相关方向上的收敛。\n",
        "nesterov=False：不使用 Nesterov 动量。\n",
        "weight_decay=0.0001：L2 正则化，防止过拟合。'''\n",
        "\n",
        "\n",
        "best_epoch, best_acc = 0.0, 0\n",
        "for epoch in range(args.num_epoch):\n",
        "    train(model, train_loader, criterion, optimizer)\n",
        "    accuracy = test(model, test_loader)\n",
        "    if accuracy > best_acc:\n",
        "        patience = 0\n",
        "        best_acc = accuracy\n",
        "        best_epoch = epoch\n",
        "        best_model = copy.deepcopy(model)\n",
        "        torch.save(best_model.state_dict(), 'best_model_cifar10h.pth.tar')\n",
        "    print('epoch: {}  acc: {:.4f}  best epoch: {}  best acc: {:.4f}'.format(\n",
        "            epoch, accuracy, best_epoch, best_acc, optimizer.param_groups[0]['lr']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rpOrSuEFY2N",
        "outputId": "41551c42-7178-4311-85af-e3d5701cb2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:18<00:00, 9.23MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "train samples: 10000 test samples: 50000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 156MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0  acc: 0.3877  best epoch: 0  best acc: 0.3877\n",
            "epoch: 1  acc: 0.5257  best epoch: 1  best acc: 0.5257\n",
            "epoch: 2  acc: 0.6194  best epoch: 2  best acc: 0.6194\n",
            "epoch: 3  acc: 0.6913  best epoch: 3  best acc: 0.6913\n",
            "epoch: 4  acc: 0.1000  best epoch: 3  best acc: 0.6913\n",
            "epoch: 5  acc: 0.1000  best epoch: 3  best acc: 0.6913\n",
            "epoch: 6  acc: 0.2263  best epoch: 3  best acc: 0.6913\n",
            "epoch: 7  acc: 0.4069  best epoch: 3  best acc: 0.6913\n",
            "epoch: 8  acc: 0.4915  best epoch: 3  best acc: 0.6913\n",
            "epoch: 9  acc: 0.4941  best epoch: 3  best acc: 0.6913\n",
            "epoch: 10  acc: 0.5760  best epoch: 3  best acc: 0.6913\n",
            "epoch: 11  acc: 0.5736  best epoch: 3  best acc: 0.6913\n",
            "epoch: 12  acc: 0.5678  best epoch: 3  best acc: 0.6913\n",
            "epoch: 13  acc: 0.5400  best epoch: 3  best acc: 0.6913\n",
            "epoch: 14  acc: 0.6472  best epoch: 3  best acc: 0.6913\n",
            "epoch: 15  acc: 0.6299  best epoch: 3  best acc: 0.6913\n",
            "epoch: 16  acc: 0.6520  best epoch: 3  best acc: 0.6913\n",
            "epoch: 17  acc: 0.6176  best epoch: 3  best acc: 0.6913\n",
            "epoch: 18  acc: 0.6466  best epoch: 3  best acc: 0.6913\n",
            "epoch: 19  acc: 0.6521  best epoch: 3  best acc: 0.6913\n",
            "epoch: 20  acc: 0.6510  best epoch: 3  best acc: 0.6913\n",
            "epoch: 21  acc: 0.6352  best epoch: 3  best acc: 0.6913\n",
            "epoch: 22  acc: 0.6416  best epoch: 3  best acc: 0.6913\n",
            "epoch: 23  acc: 0.6225  best epoch: 3  best acc: 0.6913\n",
            "epoch: 24  acc: 0.6989  best epoch: 24  best acc: 0.6989\n",
            "epoch: 25  acc: 0.6940  best epoch: 24  best acc: 0.6989\n",
            "epoch: 26  acc: 0.6729  best epoch: 24  best acc: 0.6989\n",
            "epoch: 27  acc: 0.7041  best epoch: 27  best acc: 0.7041\n",
            "epoch: 28  acc: 0.7061  best epoch: 28  best acc: 0.7061\n",
            "epoch: 29  acc: 0.6704  best epoch: 28  best acc: 0.7061\n",
            "epoch: 30  acc: 0.7058  best epoch: 28  best acc: 0.7061\n",
            "epoch: 31  acc: 0.7041  best epoch: 28  best acc: 0.7061\n",
            "epoch: 32  acc: 0.6961  best epoch: 28  best acc: 0.7061\n",
            "epoch: 33  acc: 0.7016  best epoch: 28  best acc: 0.7061\n",
            "epoch: 34  acc: 0.7046  best epoch: 28  best acc: 0.7061\n",
            "epoch: 35  acc: 0.6959  best epoch: 28  best acc: 0.7061\n",
            "epoch: 36  acc: 0.6888  best epoch: 28  best acc: 0.7061\n",
            "epoch: 37  acc: 0.7182  best epoch: 37  best acc: 0.7182\n",
            "epoch: 38  acc: 0.6892  best epoch: 37  best acc: 0.7182\n",
            "epoch: 39  acc: 0.6909  best epoch: 37  best acc: 0.7182\n",
            "epoch: 40  acc: 0.7020  best epoch: 37  best acc: 0.7182\n",
            "epoch: 41  acc: 0.6969  best epoch: 37  best acc: 0.7182\n",
            "epoch: 42  acc: 0.7093  best epoch: 37  best acc: 0.7182\n",
            "epoch: 43  acc: 0.7120  best epoch: 37  best acc: 0.7182\n",
            "epoch: 44  acc: 0.7159  best epoch: 37  best acc: 0.7182\n",
            "epoch: 45  acc: 0.6792  best epoch: 37  best acc: 0.7182\n",
            "epoch: 46  acc: 0.7132  best epoch: 37  best acc: 0.7182\n",
            "epoch: 47  acc: 0.7201  best epoch: 47  best acc: 0.7201\n",
            "epoch: 48  acc: 0.7081  best epoch: 47  best acc: 0.7201\n",
            "epoch: 49  acc: 0.7112  best epoch: 47  best acc: 0.7201\n",
            "epoch: 50  acc: 0.7023  best epoch: 47  best acc: 0.7201\n",
            "epoch: 51  acc: 0.7131  best epoch: 47  best acc: 0.7201\n",
            "epoch: 52  acc: 0.7292  best epoch: 52  best acc: 0.7292\n",
            "epoch: 53  acc: 0.7112  best epoch: 52  best acc: 0.7292\n",
            "epoch: 54  acc: 0.7158  best epoch: 52  best acc: 0.7292\n",
            "epoch: 55  acc: 0.7157  best epoch: 52  best acc: 0.7292\n",
            "epoch: 56  acc: 0.7175  best epoch: 52  best acc: 0.7292\n",
            "epoch: 57  acc: 0.7141  best epoch: 52  best acc: 0.7292\n",
            "epoch: 58  acc: 0.7257  best epoch: 52  best acc: 0.7292\n",
            "epoch: 59  acc: 0.7217  best epoch: 52  best acc: 0.7292\n",
            "epoch: 60  acc: 0.7180  best epoch: 52  best acc: 0.7292\n",
            "epoch: 61  acc: 0.7176  best epoch: 52  best acc: 0.7292\n",
            "epoch: 62  acc: 0.7216  best epoch: 52  best acc: 0.7292\n",
            "epoch: 63  acc: 0.7278  best epoch: 52  best acc: 0.7292\n",
            "epoch: 64  acc: 0.7174  best epoch: 52  best acc: 0.7292\n",
            "epoch: 65  acc: 0.7147  best epoch: 52  best acc: 0.7292\n",
            "epoch: 66  acc: 0.7144  best epoch: 52  best acc: 0.7292\n",
            "epoch: 67  acc: 0.7263  best epoch: 52  best acc: 0.7292\n",
            "epoch: 68  acc: 0.7170  best epoch: 52  best acc: 0.7292\n",
            "epoch: 69  acc: 0.7241  best epoch: 52  best acc: 0.7292\n",
            "epoch: 70  acc: 0.7243  best epoch: 52  best acc: 0.7292\n",
            "epoch: 71  acc: 0.7104  best epoch: 52  best acc: 0.7292\n",
            "epoch: 72  acc: 0.7290  best epoch: 52  best acc: 0.7292\n",
            "epoch: 73  acc: 0.7293  best epoch: 73  best acc: 0.7293\n",
            "epoch: 74  acc: 0.7253  best epoch: 73  best acc: 0.7293\n",
            "epoch: 75  acc: 0.7293  best epoch: 75  best acc: 0.7293\n",
            "epoch: 76  acc: 0.7287  best epoch: 75  best acc: 0.7293\n",
            "epoch: 77  acc: 0.7279  best epoch: 75  best acc: 0.7293\n",
            "epoch: 78  acc: 0.7347  best epoch: 78  best acc: 0.7347\n",
            "epoch: 79  acc: 0.7319  best epoch: 78  best acc: 0.7347\n",
            "epoch: 80  acc: 0.7227  best epoch: 78  best acc: 0.7347\n",
            "epoch: 81  acc: 0.7349  best epoch: 81  best acc: 0.7349\n",
            "epoch: 82  acc: 0.7308  best epoch: 81  best acc: 0.7349\n",
            "epoch: 83  acc: 0.7302  best epoch: 81  best acc: 0.7349\n",
            "epoch: 84  acc: 0.7350  best epoch: 84  best acc: 0.7350\n",
            "epoch: 85  acc: 0.7338  best epoch: 84  best acc: 0.7350\n",
            "epoch: 86  acc: 0.7217  best epoch: 84  best acc: 0.7350\n",
            "epoch: 87  acc: 0.7312  best epoch: 84  best acc: 0.7350\n",
            "epoch: 88  acc: 0.7285  best epoch: 84  best acc: 0.7350\n",
            "epoch: 89  acc: 0.7330  best epoch: 84  best acc: 0.7350\n",
            "epoch: 90  acc: 0.7388  best epoch: 90  best acc: 0.7388\n",
            "epoch: 91  acc: 0.7326  best epoch: 90  best acc: 0.7388\n",
            "epoch: 92  acc: 0.7329  best epoch: 90  best acc: 0.7388\n",
            "epoch: 93  acc: 0.7359  best epoch: 90  best acc: 0.7388\n",
            "epoch: 94  acc: 0.7311  best epoch: 90  best acc: 0.7388\n",
            "epoch: 95  acc: 0.7256  best epoch: 90  best acc: 0.7388\n",
            "epoch: 96  acc: 0.7345  best epoch: 90  best acc: 0.7388\n",
            "epoch: 97  acc: 0.7400  best epoch: 97  best acc: 0.7400\n",
            "epoch: 98  acc: 0.7301  best epoch: 97  best acc: 0.7400\n",
            "epoch: 99  acc: 0.7297  best epoch: 97  best acc: 0.7400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_probability as tfp\n",
        "\n",
        "def evaluation_all(model, testloader):\n",
        "    model.eval()\n",
        "    logits_list = []\n",
        "    labels_list = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1) #outputs returns the max value and index of the maximum output in the dimension 1\n",
        "            total += targets.size(0) #size of 0th dimension-batch size\n",
        "            correct += predicted.eq(targets).sum().item()#predicted.eq(targets).sum().item() 的最终目的是计算在当前批次中，模型预测正确的样本数量。.sum求一个布尔张量中true的个数，结果是一个张量，item帮助将张量转化为python数字\n",
        "            logits_list.append(outputs)\n",
        "            labels_list.append(targets)\n",
        "\n",
        "        logits = torch.cat(logits_list).cpu().numpy()\n",
        "        labels = torch.cat(labels_list).cpu().numpy()\n",
        "    return correct / total, logits, labels\n",
        "\n",
        "model.load_state_dict(torch.load('best_model_cifar10h.pth.tar'))#load the best combination of parameters to current model\n",
        "acc, logits_tf, labels_tf = evaluation_all(model, test_loader)\n",
        "ece = tfp.stats.expected_calibration_error(args.num_classes, logits=logits_tf, labels_true=labels_tf, labels_predicted=np.argmax(logits_tf,1))\n",
        "print(\"Acc:{:.4f}, ECE:{:.4f}\".format(acc, np.array(ece)))"
      ],
      "metadata": {
        "id": "krBAqR41UU7p",
        "outputId": "7962fb33-d008-46c1-8c99-b9c0378f9e39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-55214cfbd0b7>:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_model_cifar10h.pth.tar'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc:0.7400, ECE:0.1870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LDzFULkNDA2t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}